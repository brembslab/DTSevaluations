rawdata <- read.table(text=xmlSApply(flyDataXMLtop[['timeseries']][['csv_data']], xmlValue), col.names=variables$type)
##reset periods to start from 1 of they start from 0
if (rawdata$period[1]==0){rawdata$period=rawdata$period+1}
##reset position data to +/-180° [-1800..1796] for torquemeter experiments
if (tolower(ExperimentType)=="torquemeter"){
if (experiment$arena_type=="lightguides"){rawdata$a_pos = rawdata$a_pos-1800}
if (experiment$arena_type=="motor"){rawdata$a_pos = round(rawdata$a_pos*0.87890625)}
}
##change j_pos data from float to integer and shift to make approx. zero symmetric (needs work!)
if(exists("j_pos", rawdata)){
rawdata$j_pos = round(rawdata$j_pos*1000)+1100
}
##change a_pos data from float to integer in Joystick experiments
if(experiment$meter_type=="Joystick"){
rawdata$a_pos = round(rawdata$a_pos*1000)
}
##replace column name for fly behavior (torque, j_pos) with "fly"
colnames(rawdata) = gsub("torque", "fly", colnames(rawdata))
colnames(rawdata) = gsub("j_pos", "fly", colnames(rawdata))
##find range of fly behavior values
flyrange = range(rawdata$fly)
##calculate actual sampling rate and downsample if necessary
real_sample_rate = nrow(rawdata)/(rawdata$time[nrow(rawdata)]/1000)
NofDatapoints = as.numeric(as.character(experiment$duration))*20 #find the number of data points we should be having at 20Hz
a_posShifted <- data.frame("a_pos" = rawdata$a_pos+1800, "period" = rawdata$period) #shift position data by 180°
# create the vectors in which to save the downsampled data
a_posDownsampled <- vector(mode = "numeric")
a_posShiftedDownsampled <- vector(mode = "numeric") #second vector for 180° shifted positon data
flyDownsampled <- vector(mode = "numeric")
periodDownsampled <- vector(mode = "numeric", length = NofDatapoints)
# create new time and period values
timeDownsampled = seq(0, (as.numeric(as.character(experiment$duration))*1000)-50, 50)
p=1
t=0
for (index in 1:NofDatapoints){
periodDownsampled[index]=p
if (index == t+20*as.numeric(as.character(sequence$duration[p])))
{
t=t+20*as.numeric(as.character(sequence$duration[p]))
p=p+1
}
}
# downsample fly behavior and a_pos
for (index in 1:NofPeriods){
f=approx(subset(rawdata$fly, rawdata$period==index), n=table(periodDownsampled)[index])$y
flyDownsampled=c(flyDownsampled, round(f))
p=approx(subset(rawdata$a_pos, rawdata$period==index), n=table(periodDownsampled)[index])$y
a_posDownsampled=c(a_posDownsampled, round(p))
p2=approx(subset(a_posShifted$a_pos, a_posShifted$period==index), n=table(periodDownsampled)[index])$y
a_posShiftedDownsampled=c(a_posShiftedDownsampled, round(p2))
}
a_posDownsampled[!(a_posDownsampled %in% a_posShiftedDownsampled)]
a_posShiftedDownsampled = a_posShiftedDownsampled-1800
a_posDownsampled[!(a_posDownsampled %in% a_posShiftedDownsampled)]
rawdata$group_num <- 50*round(rawdata$time/50) # Create 50ms bins
rawdata$weight <- 1/(1+abs(rawdata$time-rawdata$group_num)) # calculate distance from measurement point
rawdata$norm <-ave(rawdata$weight,rawdata$group_num,FUN=function(x) x/sum(x)) #apply weights according to distance from bin center
rawdata$fly2 <- rawdata$fly*rawdata$norm
rawdata$a_pos2 <- rawdata$a_pos*rawdata$norm #needs more work because of values at +/-180°!!!
rawdata$period2 <- rawdata$period*rawdata$norm
# create the vectors in which to save the downsampled data
timeDownsampled2 <- as.vector(unique(rawdata$group_num))
a_posDownsampled2 <- as.vector(round(tapply(rawdata$a_pos2, rawdata$group_num, sum)))
flyDownsampled2 <- as.vector(round(tapply(rawdata$fly2, rawdata$group_num, sum)))
periodDownsampled2 <- as.vector(round(tapply(rawdata$period2, rawdata$group_num, sum)))
# bind the downsampled vectors into one dataframe
rawdataDown <- data.frame("time" = timeDownsampled2, "a_pos" = a_posDownsampled2, "fly" = flyDownsampled2, "period" = periodDownsampled2)
### check the dataframe for consistency
if (length(table(rawdataDown$period)) > NofPeriods) {rawdataDown<-rawdataDown[!(rawdataDown$period==length(table(rawdataDown$period))),]} #remove any extra period numbers, if they exist
# check if there are periods which deviate from projected duration
difference = as.data.frame(table(rawdataDown$period)) #generate dataframe with actual numbers of data points
difference$duration = as.numeric(as.character(sequence$duration))*20 # add column with expected values from sequence$duration @ 20Hz
difference$deviation = difference$Freq-difference$duration
if(any(abs(as.numeric(difference$deviation))>1)) stop("Number of data points does not match expectations. Check DTS Rawdata!") #check if there is more than one missing/additional data point
diff_periods = rownames(difference)[difference$deviation!=0] #find periods with differing numbers of data points
#mark the last data pont of each offending period (assuming we're only one data point off!)
if (length(diff_periods)!=0){
rawdataDown$last = NA
rawdataDown$last = with(rawdataDown, ave(last, match(rawdataDown$period, diff_periods), FUN = function(x) ifelse(seq_along(x) == length(x), 1, x))) # "1" marking the last data püoint in an offending period
#mark the last data points of periods with missing data points
if (length(rownames(difference)[difference$deviation==-1])!=0){ #if there are periods with too few data points, duplicate the last
negative_periods=rownames(difference)[difference$deviation==-1] #find the periods with missing values
rawdataDown$last = with(rawdataDown, ave(last, match(rawdataDown$period, negative_periods), FUN = function(x) ifelse(seq_along(x) == length(x), 2, x))) # "2" marking the last data püoint in an offending period
copy = as.vector(rawdataDown[is.element(rawdataDown$last, 2),])
copy$last=NA
for (z in 1:length(negative_periods)) {
temp.pos=as.numeric(rownames(copy[z,])) #find the right position to insert
next.pos=temp.pos+1                     #for some reason, R also wants to have the next position as a variable
rawdataDown <- rbind(rawdataDown[1:temp.pos,], copy[z,], rawdataDown[next.pos:nrow(rawdataDown),]) # duplicate the last data point in the offending periods
}
}
rawdataDown <- rawdataDown[!(grepl(1, rawdataDown$last)),] # delete last data point of the offending periods
rawdataDown$last <- NULL #delete the unnecessary 'last' column
rawdataDown$time = seq(0, (as.numeric(as.character(experiment$duration))*1000)-50, by=50) # fix the mangled time column
row.names(rawdataDown) <- 1:nrow(rawdataDown) #fix rownames, too
}
plot(a_posDownsampled, a_posDownsampled2)
a_posDownsampled2 = head(a_posDownsampled2, -3)
plot(a_posDownsampled, a_posDownsampled2)
rawdata$a_pos_shifted <- rawdata$a_pos+1800
rawdata$a_pos_shifted2 <- rawdata$a_pos_shifted*rawdata$norm
a_posShiftedDownsampled2 <- as.vector(round(tapply(rawdata$a_pos_shifted2, rawdata$group_num, sum)))
a_posShiftedDownsampled2 = a_posShiftedDownsampled2-1800
plot(a_posDownsampled, a_posDownsampled2)
plot(a_posShiftedDownsampled2, a_posDownsampled2)
a_posDownsampled2 = head(a_posShiftedDownsampled2, -3)
plot(a_posShiftedDownsampled2, a_posDownsampled2)
rawdata$group_num <- 50*round(rawdata$time/50) # Create 50ms bins
rawdata$weight <- 1/(1+abs(rawdata$time-rawdata$group_num)) # calculate distance from measurement point
rawdata$norm <-ave(rawdata$weight,rawdata$group_num,FUN=function(x) x/sum(x)) #apply weights according to distance from bin center
rawdata$fly2 <- rawdata$fly*rawdata$norm
rawdata$a_pos2 <- rawdata$a_pos*rawdata$norm #needs more work because of values at +/-180°!!!
rawdata$period2 <- rawdata$period*rawdata$norm
rawdata$a_pos_shifted <- rawdata$a_pos+1800
rawdata$a_pos_shifted2 <- rawdata$a_pos_shifted*rawdata$norm
# create the vectors in which to save the downsampled data
timeDownsampled2 <- as.vector(unique(rawdata$group_num))
a_posDownsampled2 <- as.vector(round(tapply(rawdata$a_pos2, rawdata$group_num, sum)))
flyDownsampled2 <- as.vector(round(tapply(rawdata$fly2, rawdata$group_num, sum)))
periodDownsampled2 <- as.vector(round(tapply(rawdata$period2, rawdata$group_num, sum)))
a_posShiftedDownsampled2 <- as.vector(round(tapply(rawdata$a_pos_shifted2, rawdata$group_num, sum)))
a_posShiftedDownsampled2 = a_posShiftedDownsampled2-1800
# bind the downsampled vectors into one dataframe
rawdataDown <- data.frame("time" = timeDownsampled2, "a_pos" = a_posDownsampled2, "fly" = flyDownsampled2, "period" = periodDownsampled2)
### check the dataframe for consistency
if (length(table(rawdataDown$period)) > NofPeriods) {rawdataDown<-rawdataDown[!(rawdataDown$period==length(table(rawdataDown$period))),]} #remove any extra period numbers, if they exist
# check if there are periods which deviate from projected duration
difference = as.data.frame(table(rawdataDown$period)) #generate dataframe with actual numbers of data points
difference$duration = as.numeric(as.character(sequence$duration))*20 # add column with expected values from sequence$duration @ 20Hz
difference$deviation = difference$Freq-difference$duration
if(any(abs(as.numeric(difference$deviation))>1)) stop("Number of data points does not match expectations. Check DTS Rawdata!") #check if there is more than one missing/additional data point
diff_periods = rownames(difference)[difference$deviation!=0] #find periods with differing numbers of data points
#mark the last data pont of each offending period (assuming we're only one data point off!)
if (length(diff_periods)!=0){
rawdataDown$last = NA
rawdataDown$last = with(rawdataDown, ave(last, match(rawdataDown$period, diff_periods), FUN = function(x) ifelse(seq_along(x) == length(x), 1, x))) # "1" marking the last data püoint in an offending period
#mark the last data points of periods with missing data points
if (length(rownames(difference)[difference$deviation==-1])!=0){ #if there are periods with too few data points, duplicate the last
negative_periods=rownames(difference)[difference$deviation==-1] #find the periods with missing values
rawdataDown$last = with(rawdataDown, ave(last, match(rawdataDown$period, negative_periods), FUN = function(x) ifelse(seq_along(x) == length(x), 2, x))) # "2" marking the last data püoint in an offending period
copy = as.vector(rawdataDown[is.element(rawdataDown$last, 2),])
copy$last=NA
for (z in 1:length(negative_periods)) {
temp.pos=as.numeric(rownames(copy[z,])) #find the right position to insert
next.pos=temp.pos+1                     #for some reason, R also wants to have the next position as a variable
rawdataDown <- rbind(rawdataDown[1:temp.pos,], copy[z,], rawdataDown[next.pos:nrow(rawdataDown),]) # duplicate the last data point in the offending periods
}
}
rawdataDown <- rawdataDown[!(grepl(1, rawdataDown$last)),] # delete last data point of the offending periods
rawdataDown$last <- NULL #delete the unnecessary 'last' column
rawdataDown$time = seq(0, (as.numeric(as.character(experiment$duration))*1000)-50, by=50) # fix the mangled time column
row.names(rawdataDown) <- 1:nrow(rawdataDown) #fix rownames, too
}
plot(a_posShiftedDownsampled2, a_posDownsampled2)
plot(rawdata$a_pos, rawdata$a_pos_shifted)
rawdata$group_num <- 50*round(rawdata$time/50) # Create 50ms bins
rawdata$weight <- 1/(1+abs(rawdata$time-rawdata$group_num)) # calculate distance from measurement point
rawdata$norm <-ave(rawdata$weight,rawdata$group_num,FUN=function(x) x/sum(x)) #apply weights according to distance from bin center
rawdata$fly2 <- rawdata$fly*rawdata$norm
rawdata$a_pos2 <- rawdata$a_pos*rawdata$norm #needs more work because of values at +/-180°!!!
rawdata$period2 <- rawdata$period*rawdata$norm
rawdata$a_pos_shifted <- rawdata$a_pos+900
rawdata$a_pos_shifted2 <- rawdata$a_pos_shifted*rawdata$norm
# create the vectors in which to save the downsampled data
timeDownsampled2 <- as.vector(unique(rawdata$group_num))
a_posDownsampled2 <- as.vector(round(tapply(rawdata$a_pos2, rawdata$group_num, sum)))
flyDownsampled2 <- as.vector(round(tapply(rawdata$fly2, rawdata$group_num, sum)))
periodDownsampled2 <- as.vector(round(tapply(rawdata$period2, rawdata$group_num, sum)))
a_posShiftedDownsampled2 <- as.vector(round(tapply(rawdata$a_pos_shifted2, rawdata$group_num, sum)))
a_posShiftedDownsampled2 = a_posShiftedDownsampled2-900
# bind the downsampled vectors into one dataframe
rawdataDown <- data.frame("time" = timeDownsampled2, "a_pos" = a_posDownsampled2, "fly" = flyDownsampled2, "period" = periodDownsampled2)
### check the dataframe for consistency
if (length(table(rawdataDown$period)) > NofPeriods) {rawdataDown<-rawdataDown[!(rawdataDown$period==length(table(rawdataDown$period))),]} #remove any extra period numbers, if they exist
# check if there are periods which deviate from projected duration
difference = as.data.frame(table(rawdataDown$period)) #generate dataframe with actual numbers of data points
difference$duration = as.numeric(as.character(sequence$duration))*20 # add column with expected values from sequence$duration @ 20Hz
difference$deviation = difference$Freq-difference$duration
if(any(abs(as.numeric(difference$deviation))>1)) stop("Number of data points does not match expectations. Check DTS Rawdata!") #check if there is more than one missing/additional data point
diff_periods = rownames(difference)[difference$deviation!=0] #find periods with differing numbers of data points
#mark the last data pont of each offending period (assuming we're only one data point off!)
if (length(diff_periods)!=0){
rawdataDown$last = NA
rawdataDown$last = with(rawdataDown, ave(last, match(rawdataDown$period, diff_periods), FUN = function(x) ifelse(seq_along(x) == length(x), 1, x))) # "1" marking the last data püoint in an offending period
#mark the last data points of periods with missing data points
if (length(rownames(difference)[difference$deviation==-1])!=0){ #if there are periods with too few data points, duplicate the last
negative_periods=rownames(difference)[difference$deviation==-1] #find the periods with missing values
rawdataDown$last = with(rawdataDown, ave(last, match(rawdataDown$period, negative_periods), FUN = function(x) ifelse(seq_along(x) == length(x), 2, x))) # "2" marking the last data püoint in an offending period
copy = as.vector(rawdataDown[is.element(rawdataDown$last, 2),])
copy$last=NA
for (z in 1:length(negative_periods)) {
temp.pos=as.numeric(rownames(copy[z,])) #find the right position to insert
next.pos=temp.pos+1                     #for some reason, R also wants to have the next position as a variable
rawdataDown <- rbind(rawdataDown[1:temp.pos,], copy[z,], rawdataDown[next.pos:nrow(rawdataDown),]) # duplicate the last data point in the offending periods
}
}
rawdataDown <- rawdataDown[!(grepl(1, rawdataDown$last)),] # delete last data point of the offending periods
rawdataDown$last <- NULL #delete the unnecessary 'last' column
rawdataDown$time = seq(0, (as.numeric(as.character(experiment$duration))*1000)-50, by=50) # fix the mangled time column
row.names(rawdataDown) <- 1:nrow(rawdataDown) #fix rownames, too
}
plot(a_posShiftedDownsampled2, a_posDownsampled2)
NofDatapoints = as.numeric(as.character(experiment$duration))*20 #find the number of data points we should be having at 20Hz
a_posShifted <- data.frame("a_pos" = rawdata$a_pos+900, "period" = rawdata$period) #shift position data by 180°
# create the vectors in which to save the downsampled data
a_posDownsampled <- vector(mode = "numeric")
a_posShiftedDownsampled <- vector(mode = "numeric") #second vector for 180° shifted positon data
flyDownsampled <- vector(mode = "numeric")
periodDownsampled <- vector(mode = "numeric", length = NofDatapoints)
# create new time and period values
timeDownsampled = seq(0, (as.numeric(as.character(experiment$duration))*1000)-50, 50)
p=1
t=0
for (index in 1:NofDatapoints){
periodDownsampled[index]=p
if (index == t+20*as.numeric(as.character(sequence$duration[p])))
{
t=t+20*as.numeric(as.character(sequence$duration[p]))
p=p+1
}
}
# downsample fly behavior and a_pos
for (index in 1:NofPeriods){
f=approx(subset(rawdata$fly, rawdata$period==index), n=table(periodDownsampled)[index])$y
flyDownsampled=c(flyDownsampled, round(f))
p=approx(subset(rawdata$a_pos, rawdata$period==index), n=table(periodDownsampled)[index])$y
a_posDownsampled=c(a_posDownsampled, round(p))
p2=approx(subset(a_posShifted$a_pos, a_posShifted$period==index), n=table(periodDownsampled)[index])$y
a_posShiftedDownsampled=c(a_posShiftedDownsampled, round(p2))
}
#replace +/-180° datapoints with the shifted downsampled data
a_posShiftedDownsampled = a_posShiftedDownsampled-900
plot(a_posShiftedDownsampled, a_posDownsampled)
a_posDownsampled[!(a_posDownsampled %in% a_posShiftedDownsampled)]
plot(rawdata$a_pos, rawdata$a_pos_shifted)
install.packages("dabestr")
install.packages("dabestr")
library(dabestr)
library(ggplot2)
library(tidyr)
library(dygraphs)
library(grid)
library(reshape2)
library(dplyr)
library(plyr)
library(gridExtra)
library(yaml)
library(ggsignif)
library(effsize)
library(pwr)
library(BayesFactor)
library(genefilter)
library(seewave)
library(lubridate)
library(rmarkdown)
library(markdown)
library(knitr)
install.packages("digest")
library(ggplot2)
library(tidyr)
library(dygraphs)
library(grid)
library(reshape2)
library(plyr)
library(dplyr)
library(gridExtra)
library(yaml)
library(ggsignif)
library(effsize)
library(pwr)
library(BayesFactor)
library(genefilter)
install.packages("mvtnorm")
install.packages("RSQLite")
library(BayesFactor)
library(genefilter)
library(seewave)
library(lubridate)
library(rmarkdown)
library(markdown)
library(knitr)
library(zoo)
library(dabestr)
install.packages("dabestr")
install.packages(c("httr", "knitr", "markdown", "nlme", "pkgbuild", "tinytex"))
install.packages(c("httr", "knitr", "markdown", "nlme", "pkgbuild", "tinytex"))
devtools::install_github("ACCLAB/dabestr")
install.packages("dabestr")
install.packages("dabestr")
library(dabestr)
install.packages("dabestr")
install.packages("rlang")
install.packages(c("dplyr", "ggsignif", "knitr", "markdown", "Rcpp", "rlang", "tibble", "tinytex"))
install.packages(c("ggforce", "ggplot2", "ggsignif", "knitr", "markdown", "tinytex"))
install.packages("dabestr")
View(fly)
install.packages(c("digest", "ellipsis", "ggforce", "knitr", "mgcv", "pbapply", "pkgconfig", "rmarkdown", "tidyr", "tinytex", "xfun"))
install.packages("dabestr")
install.packages(c("backports", "BiocManager", "callr", "curl", "data.table", "devtools", "digest", "ellipsis", "ggforce", "ggplot2", "ggsignif", "hms", "htmltools", "htmlwidgets", "httr", "knitr", "markdown", "mgcv", "modelr", "nlme", "pbapply", "pkgbuild", "pkgconfig", "rmarkdown", "sys", "tidyr", "tinytex", "TTR", "whisker", "xfun", "xml2"))
install.packages(c("BiocManager", "htmlwidgets", "nlme"))
install.packages("dabestr")
install.packages("dabestr")
install.packages("dabestr")
q()
install.packages(c("BiocManager", "boot", "foreign", "htmlwidgets", "mgcv", "nlme"))
(log(4500)-log(1800))/log(1.05)
(log(5000)-log(1800))/log(1.06)
(log(5000)-log(3300))/log(1.06)
(log(5000)-log(2000))/log(1.06)
(log(5000)-log(3600))/log(1.06)
View(experiment)
View(sequence)
View(sequence)
ggplot(data=all.data, aes_string(all.data$a_pos)) +
geom_histogram(binwidth=10) +
labs(x="position [arb units]", y="frequency") +
xlim(-1800,1800) +
ggtitle("Pooled Position Histogram")
library(ggplot2)
load("B:/GitHub/DTSevaluations/example data/colorlearning/.RData")
ggplot(data=all.data, aes_string(all.data$a_pos)) +
geom_histogram(binwidth=10) +
labs(x="position [arb units]", y="frequency") +
xlim(-1800,1800) +
ggtitle("Pooled Position Histogram")
View(PIprofile)
table(sign(temp$fly))
View(temp)
table(sign(temp$torque))
View(PIprofile)
View(exp_groups)
install.packages(c("bit", "broom", "callr", "car", "class", "cli", "covr", "crosstalk", "dabestr", "deSolve", "devtools", "digest", "dplyr", "DT", "effsize", "forcats", "foreign", "fs", "ggplot2", "ggrepel", "glue", "knitr", "lattice", "lifecycle", "mime", "modelr", "mvtnorm", "nlme", "nloptr", "nnet", "plyr", "processx", "ps", "pwr", "Rcpp", "remotes", "rlang", "roxygen2", "rstudioapi", "shiny", "stringi", "survival", "testthat", "tinytex", "vctrs", "xml2"))
install.packages(c("bit", "broom", "callr", "car", "class", "cli", "covr", "crosstalk", "dabestr", "deSolve", "devtools", "digest", "dplyr", "DT", "effsize", "forcats", "foreign", "fs", "ggplot2", "ggrepel", "glue", "knitr", "lattice", "lifecycle", "mime", "modelr", "mvtnorm", "nlme", "nloptr", "nnet", "plyr", "processx", "ps", "pwr", "Rcpp", "remotes", "rlang", "roxygen2", "rstudioapi", "shiny", "stringi", "survival", "testthat", "tinytex", "vctrs", "xml2"))
install.packages(c("dplyr", "glue", "Rcpp", "rlang"))
install.packages(c("dplyr", "glue", "Rcpp", "rlang"))
install.packages(c("dplyr", "glue", "Rcpp", "rlang"))
install.packages(c("dplyr", "glue", "Rcpp", "rlang"))
install.packages(c("dplyr", "glue", "Rcpp", "rlang"))
install.packages(c("dplyr", "glue", "Rcpp", "rlang"))
install.packages(c("dplyr", "glue", "Rcpp", "rlang"))
install.packages(c("dplyr", "glue", "Rcpp", "rlang"))
install.packages(c("dplyr", "glue", "Rcpp", "rlang"))
install.packages(c("dplyr", "glue", "Rcpp", "rlang"))
install.packages(c("dplyr", "glue", "Rcpp", "rlang"))
install.packages(c("dplyr", "glue", "Rcpp", "rlang"))
rm(list=ls()) #clean memory
gc()          #collect garbage
install.packages(c("dplyr", "glue", "Rcpp", "rlang"))
install.packages("Rcpp")
rm(list=ls()) #clean memory
gc()          #collect garbage
install.packages("Rcpp")
install.packages("Rcpp")
rm(list=ls()) #clean memory
gc()          #collect garbage
install.packages("Rcpp")
install.packages("Rcpp")
load("~/buridan_ottavia.RData")
View(bf.activity)
bf.activity[3]
bf.activity$bayesFactor
bf.activity[[3]]
bf.activity[3]
bf.activity[1]
bf.activity[2]
bf.activity[3]
bf.activity[4]
bf.activity$bf
bf.activity[3]$bf
bf.activity[,1]
bf.activity[,2]
bf.activity
bf.distance
bf.fixation
bf.meander
bf.speed
View(buri.data)
mean(buri.data$median_speed[1:21])
mean(buri.data$median_speed[22:42])
sd(buri.data$median_speed[1:21])
sd(buri.data$median_speed[22:42])
sd(buri.data$median_speed)
sd(buri.data$meander)
mean(buri.data$meander[22:42])
mean(buri.data$meander[1:21])
sd(buri.data$activitytime_ST)
mean(buri.data$activitytime_ST[1:21])
mean(buri.data$activitytime_ST[22:42])
mean(buri.data$stripe_deviation[1:21])
mean(buri.data$stripe_deviation[2:42])
mean(buri.data$stripe_deviation)
sd(buri.data$stripe_deviation)
cohend.stripe = signif(cohen.d(buri.data$stripe_deviation[1:21], buri.data$stripe_deviation[2:42])$estimate, 3)
knitr::opts_chunk$set(echo = TRUE)
library(effsize)
cohend.stripe = signif(cohen.d(buri.data$stripe_deviation[1:21], buri.data$stripe_deviation[2:42])$estimate, 3)
power.stripe=signif(pwr.t2n.test(n1 = 21, n2= 21, d = cohend.stripe, alternative = alt, sig.level = 0.05)$power, 3)
library(pwr)
power.stripe=signif(pwr.t2n.test(n1 = 21, n2= 21, d = cohend.stripe, alternative = alt, sig.level = 0.05)$power, 3)
power.stripe=signif(pwr.t2n.test(n1 = 21, n2= 21, d = cohend.stripe, alternative = two.sided, sig.level = 0.05)$power, 3)
power.stripe=signif(pwr.t2n.test(n1 = 21, n2= 21, d = cohend.stripe, alternative = "two.sided", sig.level = 0.05)$power, 3)
sd(buri.data$stripe_deviation[1:21])
sd(buri.data$stripe_deviation[2:42])
cohen.d(buri.data$stripe_deviation[1:21], buri.data$stripe_deviation[2:42])
cohen.d(buri.data$stripe_deviation[2:42], buri.data$stripe_deviation[1:21])
(mean(buri.data$stripe_deviation[1:21])-mean(buri.data$stripe_deviation[2:42]))/sd(buri.data$stripe_deviation)
cohen.d(buri.data$stripe_deviation[2:42], buri.data$stripe_deviation[1:21], hedges.correction=TRUE)
save.image("~/buridan_ottavia.RData")
power.stripe=signif(pwr.t.test(n = 21, d = cohend.stripe, alternative = "two.sided", sig.level = 0.05)$power, 3)
pwr.t.test(n = 21, d = cohend.stripe, alternative = "two.sided", sig.level = 0.05
)
pwr.t2n.test(n1 = 21, n2= 21, d = cohend.stripe, alternative = two.sided, sig.level = 0.05)
pwr.t2n.test(n1 = 21, n2= 21, d = cohend.stripe, alternative = "two.sided", sig.level = 0.05)
(mean(buri.data$stripe_deviation[1:21])-mean(buri.data$stripe_deviation[2:42]))/sqrt((sd(buri.data$stripe_deviation[1:21]^2)-sd(buri.data$stripe_deviation[2:42]^2))/2)
(mean(buri.data$stripe_deviation[1:21])-mean(buri.data$stripe_deviation[2:42]))/sqrt((sd(buri.data$stripe_deviation[1:21])^2-sd(buri.data$stripe_deviation[2:42])^2)/2)
sd(buri.data$stripe_deviation[1:21])^2
sd(buri.data$stripe_deviation[1:21])^2-sd(buri.data$stripe_deviation[2:42])^2
(mean(buri.data$stripe_deviation[1:21])-mean(buri.data$stripe_deviation[2:42]))/sqrt((sd(buri.data$stripe_deviation[1:21])^2+sd(buri.data$stripe_deviation[2:42])^2)/2)
cohen.d(buri.data$stripe_deviation[2:42], buri.data$stripe_deviation[1:21], hedges.correction=TRUE, within=FALSE)
cohen.d(buri.data$stripe_deviation[2:42], buri.data$stripe_deviation[1:21], hedges.correction=TRUE, within=TRUE)
cohen.d(buri.data$stripe_deviation[2:42], buri.data$stripe_deviation[1:21], hedges.correction=TRUE, pooled = =TRUE)
cohen.d(buri.data$stripe_deviation[2:42], buri.data$stripe_deviation[1:21], hedges.correction=TRUE, pooled = TRUE)
cohen.d(buri.data$stripe_deviation[2:42], buri.data$stripe_deviation[1:21], hedges.correction=TRUE, pooled = FALSE)
edit(effsize:::cohen.d.default)
edit(effsize:::cohen.d.default)
save.image("~/buridan_ottavia.RData")
load("B:/GitHub/DTSevaluations/example data/colorlearning/.RData")
View(PIstat)
PIstat[[1]]
PIstat[[,1]]
if(samplesizes[1]==samplesizes[2]){equalN=TRUE}else{equalN=FALSE}   #deterine if the samplesizes are identical
PIg <- as.factor(c(rep(1, samplesizes[1]), rep(2, samplesizes[2]))) #make a grouping variable to test for homogeneity of variance
PIv = c(na.omit(PIstat[[1]]), na.omit(PIstat[[1]]))                 #combine the two PI samples into one value vector to test for homogeneity of variance
if(fligner.test(PIv,PIg)<0.05){hv=FALSE}else{hv=TRUE}               #test for homogeneity of variance and set hv TRUE/FALSE
samplesizes[1]=length(PIstat[1])
samplesizes[1]=length(PIstat[[1]])
samplesizes[2]=length(PIstat[[2]])
samplesizes[2]=length(na.omit(PIstat[[2]]))
samplesizes[1]=length(na.omit(PIstat[[1]]))
PIstat[[1]]
PIstat[1]
PIv = c(na.omit(PIstat[[1]]), na.omit(PIstat[[2]]))                 #combine the two PI samples into one value vector to test for homogeneity of variance
PIg
PIv
PIv = c(na.omit(PIstat[1]), na.omit(PIstat[2]))                 #combine the two PI samples into one value vector to test for homogeneity of variance
PIv = c(na.omit(PIstat[[1]]), na.omit(PIstat[[2]]))                 #combine the two PI samples into one value vector to test for homogeneity of variance
fligner.test(PIv,PIg)
fktest=fligner.test(PIv,PIg)
fktest$p.value
if(samplesizes[1]==samplesizes[2]){equalN=TRUE}else{equalN=FALSE}   #deterine if the samplesizes are identical
PIg <- as.factor(c(rep(1, samplesizes[1]), rep(2, samplesizes[2]))) #make a grouping variable to test for homogeneity of variance
PIv = c(na.omit(PIstat[[1]]), na.omit(PIstat[[2]]))                 #combine the two PI samples into one value vector to test for homogeneity of variance
if(fligner.test(PIv,PIg)$p.value<0.05){hv=FALSE}else{hv=TRUE}       #test for homogeneity of variance and set hv TRUE/FALSE
if(equalN & hv){hedges=FALSE}else{hedges=TRUE}                      #test if we need to apply Hedge's correction
cohend = signif(cohen.d(PIstat[,1], PIstat[,2], na.rm = TRUE, hedges.correction = hedges)$estimate, 3)
cohend = signif(cohen.d(PIstat[,1], PIstat[,2], na.rm = TRUE, hedges.correction = hedges)$estimate, 3)
PIstat[,1]
PIstat[[1]]
cohend = signif(cohen.d(PIstat[,1], PIstat[,2], na.rm = TRUE, hedges.correction = hedges, pooled = FALSE)$estimate, 3)
cohend = signif(cohen.d(PIv, PIg, hedges.correction = hedges)$estimate, 3)
cohend = signif(cohen.d(PIv, PIg)$estimate, 3)
cohend = signif(cohen.d(PIv, PIg, hedges.correction = hedges)$estimate, 3)
power=signif(pwr.t2n.test(n1 = samplesizes[1], n2= samplesizes[2], d = cohend, alternative = alt, sig.level = signif[1])$power, 3)
cohend = (mean(PIstat[[1]])-mean(PIstat[[2]]))/sqrt((sd(PIstat[[1]]^2+PIstat[[1]]^2))/2)
(mean(PIstat[[1]])-mean(PIstat[[2]])
)
mean(PIstat[[1]])
PIstat[[1]]
mean(PIstat[1])
mean(PIstat[,1])
mean(na.omit(PIstat[,1]))
sd(PIstat[[1]])
sd(PIstat[[2]])
PIstat[[1]])
sd(PIstat[[1]])
sqrt((sd(na.omit(PIstat[[1]]))^2+sd(na.omit(PIstat[[2]]))^2)/2)
(mean(na.omit(PIstat[[1]]))-mean(na.omit(PIstat[[2]])))
cohend = (mean(na.omit(PIstat[[1]]))-mean(na.omit(PIstat[[2]])))/sqrt((sd(na.omit(PIstat[[1]]))^2+sd(na.omit(PIstat[[2]]))^2)/2)
cohend = signif(cohen.d(PIv, PIg, hedges.correction = hedges)$estimate, 3)
load("B:/GitHub/DTSevaluations/.RData")
View(PIstat)
View(PIstatCombined)
cohend = signif((mean(na.omit(PIstat[[1]]))-mean(na.omit(PIstat[[2]])))/sqrt((sd(na.omit(PIstat[[1]]))^2+sd(na.omit(PIstat[[2]]))^2)/2), 3)
View(PIstat)
install.packages(c("DescTools", "questionr"))
install.packages(c("glue", "gtools", "lattice", "purrr", "Rcpp", "reshape2", "rlang", "tibble", "zoo"))
install.packages(c("glue", "gtools", "lattice", "purrr", "Rcpp", "reshape2", "rlang", "tibble", "zoo"))
install.packages(c("glue", "gtools", "lattice", "purrr", "Rcpp", "reshape2", "rlang", "tibble", "zoo"))
install.packages(c("glue", "gtools", "lattice", "purrr", "Rcpp", "reshape2", "rlang", "tibble", "zoo"))
install.packages(c("glue", "gtools", "lattice", "purrr", "Rcpp", "reshape2", "rlang", "tibble", "zoo"))
install.packages(c("glue", "gtools", "lattice", "purrr", "Rcpp", "reshape2", "rlang", "tibble", "zoo"))
install.packages(c("glue", "gtools", "lattice", "purrr", "Rcpp", "reshape2", "rlang", "tibble", "zoo"))
install.packages(c("glue", "gtools", "lattice", "purrr", "Rcpp", "reshape2", "rlang", "tibble", "zoo"))
install.packages(c("glue", "gtools", "lattice", "purrr", "Rcpp", "reshape2", "rlang", "tibble", "zoo"))
install.packages(c("glue", "gtools", "lattice", "purrr", "Rcpp", "reshape2", "rlang", "tibble", "zoo"))
rm(list=ls()) #clean memory
gc()          #collect garbage
install.packages(c("glue", "gtools", "lattice", "purrr", "Rcpp", "rlang", "tibble"))
install.packages(c("lattice", "Rcpp", "rlang"))
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
install.packages("rlang")
setwd("B:/GitHub/DTSevaluations")
source('B:/GitHub/DTSevaluations/HTML_DTS_project.R', echo=TRUE)
BiocManager::install("genefilter")
source("https://bioconductor.org/biocLite.R")
biocLite("genefilter")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install(version = "3.11")
version
