m<-nls(y~a*x/(b+x))
OMparams=as.data.frame(coef(m)) #put the results in a dataframe
View(OMparams)
test=coef(m)
test
OMmidpoint = plotOM$time[nrow(plotOM)]/2
#right turning traces
x=plotOM$time[plotOM$time<=OMmidpoint] #time
y=plotOM$means[plotOM$time<=OMmidpoint]+abs(plotOM$means[1]) #mean OM response normalized to start from zero
m<-nls(y~a*x/(b+x))
right=coef(m) #put the results in a vector
#left turning traces
x=plotOM$time[plotOM$time>OMmidpoint] #time
x=x-x[1] #set time to start from zero
y=-plotOM$means[plotOM$time>OMmidpoint] #mean OM response
y=y+abs(y[1])
m<-nls(y~a*x/(b+x))
left=coef(m)
mean(left, right)
(left+right)/2
(left-right)
(left-right)/(left+right)
(right-left)/(right+left)
as_slope=(right+left)/2 #mean asymptote and slope
asym_ind=(right-left)/(right+left) #asymmetry index
plot(as_slope)
barplot(as_slope)
barplot(asym_ind)
aveOMcoeff=(right+left)/2                                    #mean asymptote and halfmaximal time
OMasym=(right-left)/(right+left)                             #asymmetry index
aveOMcoeff[2]=aveOMcoeff[2]/1000
OMparams <- c(avecoeff, OMasym[1])
OMparams <- data.frame(avecoeff, OMasym[1])
OMparams <- data.frame(aveOMcoeff, OMasym[1])
View(OMparams)
as.numeric(aveOMcoeff)
OMparams <- data.frame(as.numeric(aveOMcoeff), as.numeric(OMasym[1]))
OMparams <- cbind(as.numeric(aveOMcoeff), as.numeric(OMasym[1]))
OMparams <- rbind(as.numeric(aveOMcoeff), as.numeric(OMasym[1]))
OMparams <- data.frame(as.numeric(aveOMcoeff))
OMparams <- rbind(as.numeric(aveOMcoeff))
OMparams$3 <- as.numeric(OMasym[1])
OMparams$v3 <- as.numeric(OMasym[1])
View(OMparams)
OMparams <- rbind(as.numeric(aveOMcoeff))
OMparams$v3 = as.numeric(OMasym[1])
OMparams <- rbind(as.numeric(aveOMcoeff))
OMparams$v3 = OMasym[1]
OMparams <- rbind(as.numeric(aveOMcoeff))
OMparams$v3 = as.data.frame(OMasym[1])
OMparams <- as.data.frame(rbind(as.numeric(aveOMcoeff)))
OMparams$v3 = as.data.frame(OMasym[1])
View(OMparams)
OMparams <- as.data.frame(rbind(as.numeric(aveOMcoeff)))
OMparams$v3 = OMasym[1]
View(OMparams)
kable(OMparams)
library(ggplot2)
library(tidyr)
library(dygraphs)
library(grid)
library(reshape2)
library(dplyr)
library(gridExtra)
library(yaml)
library(ggsignif)
library(effsize)
library(pwr)
library(BayesFactor)
library(genefilter)  # if not available for newest version: setRepositories(addURLs = c(CRANxtras = "http://www.stats.ox.ac.uk/pub/RWin"))
library(seewave)
kable(OMparams)
names(OMparams) = c("asymptote", "halfmax_time","AI")
View(OMparams)
tempOMparams <- as.data.frame(rbind(as.numeric(aveOMcoeff))) #gather asymptote and halfmaximal time
tempOMparams$v3 = OMasym[1]                                  #add asymptote asymmetry index
names(tempOMparams) = c("asymptote", "halfmax_time","AI")
rownames(tempOMparams[1])=flyname
View(tempOMparams)
flyname
as.character(flyname)
rownames(tempOMparams[1])=as.character(flyname)
View(tempOMparams)
rownames(tempOMparams[1])=as.character(flyname)
View(tempOMparams)
rownames(tempOMparams[1])
rownames(tempOMparams[1])=as.character(flyname)
rownames(tempOMparams[1])
rownames(tempOMparams)[1]=as.character(flyname)
View(tempOMdata)
View(tempOMparams)
library(knitr)
kable
kable(tempOMparams)
if(!exists("OMparams"))
{
OMparams=tempOMparams
} else {
OMparams[as.character(flyname),]=tempOMparams
}
View(OMparams)
rm(OMparams)
if(!exists("OMparams"))
{
OMparams=tempOMparams
} else {
OMparams[as.character(flyname),]=tempOMparams
}
View(OMparams)
if(!exists("OMparams"))
{
OMparams=tempOMparams
} else {
OMparams[as.character(flyname),]=tempOMparams
}
if(!exists("OMparams"))
{
OMparams=tempOMparams
} else {
OMparams[as.character(flyname),]=tempOMparams
}
View(OMparams)
View(OMparams)
OMparams[as.character(flyname),]=tempOMparams
rownames(OMparams)[1]=wtb-01
rownames(OMparams)[1]="wtb-01"
View(OMparams)
if(!exists("OMparams"))
{
OMparams=tempOMparams
} else {
OMparams[as.character(flyname),]=tempOMparams
}
View(OMparams)
load("B:/GitHub/DTSevaluations/.RData")
View(PIprofile)
View(PIstat)
load("B:/GitHub/DTSevaluations/.RData")
install.packages("dabestr")
library(dabestr)
unpaired_mean_diff <- dabest(PIstat,
paired = FALSE)
unpaired_mean_diff <- dabest(PIstat, WTB1, WTB2,
idx = c("WTB1", "WTB2"),
paired = FALSE)
PIest=PIstat
names(PIest)
insertRow()
PIest <- rbind(PIstat[1, ], names(PIstat), PIest[2:nrow(PIest), ])
View(PIest)
View(PIstat)
PIest <- rbind(PIstat[0, ], names(PIstat), PIest[1:nrow(PIest), ])
rm(PIest)
PIest <- rbind(PIstat[0, ], names(PIstat), PIest[1:nrow(PIest), ])
PIest = rbind(PIstat[0, ], names(PIstat), PIest[1:nrow(PIest), ])
PIest = as.data.frame(rbind(PIstat[0, ], names(PIstat), PIest[1:nrow(PIest), ]))
PIest <- rbind(PIstat[0, ], names(PIstat), PIstat[1:nrow(PIstat), ])
View(PIest)
unpaired_mean_diff <- dabest(PIest, WTB1, WTB2,
idx = c("WTB1", "WTB2"),
paired = FALSE)
unpaired_mean_diff <- dabest(PIest, WTB1, WTB2, paired = FALSE)
PIest=melt(PIstat)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tidyr)
library(dygraphs)
library(grid)
library(reshape2)
library(dplyr)
library(gridExtra)
library(yaml)
library(ggsignif)
library(effsize)
library(pwr)
library(BayesFactor)
library(genefilter)
library(seewave)
library(lubridate)
library(dabestr)
PIest=melt(PIstat)
unpaired_mean_diff <- dabest(PIest, WTB1, WTB2,
idx = c("WTB1", "WTB2"),
paired = FALSE)
unpaired_mean_diff <- dabest(PIest, variable, value,
idx = c("WTB1", "WTB2"),
paired = FALSE)
View(unpaired_mean_diff)
plot(unpaired_mean_diff)
load("B:/GitHub/DTSevaluations/example data/colorlearning/.RData")
PIest=melt(PIstat)
View(PIest)
PIest=melt(!is.na(PIstat))
View(PIest)
rm(PIest)
PIest=melt(!is.na(PIstat))
View(PIest)
PIest=melt(PIstat)
View(PIest)
PIest=melt(na.omit(PIstat))
View(PIest)
unpaired_mean_diff <- dabest(PIest, variable, value,
idx = c("rut", "WTB"),
paired = FALSE)
plot(unpaired_mean_diff)
View(unpaired_mean_diff)
unpaired_mean_diff <- dabest(PIest, variable, value,
idx = groupnames,
paired = FALSE)
plot(unpaired_mean_diff)
View(PIstat)
PIest=melt(PIstat)
View(PIest)
PIest=na.omit(PIest)
unpaired_mean_diff <- dabest(PIest, variable, value,
idx = groupnames,
paired = FALSE)
plot(unpaired_mean_diff)
PIest=na.omit(melt(PIstat)) #create a dataframe that fits estimation stat requirements and remove missing PIs
unpaired_mean_diff <- dabest(PIest, variable, value,
idx = groupnames,
paired = FALSE)
plot(unpaired_mean_diff)
setwd("B:/GitHub/DTSevaluations")
source('B:/GitHub/DTSevaluations/HTML_DTS_project.R', echo=TRUE)
setwd("B:/GitHub/DTSevaluations")
source('B:/GitHub/DTSevaluations/HTML_DTS_project.R', echo=TRUE)
source('B:/GitHub/DTSevaluations/HTML_DTS_project.R', echo=TRUE)
View(PIprofile)
learningscore=project.data[["statistics"]][["learning-score"]][["data"]] #get the PI that is going to be tested
if(!stat){samplesizes<-as.numeric(apply(PIstat, 2, function(x) length(na.omit(x))))}
#create new dataframe with only the chosen PI values
PIstat <- list()
for(x in 1:NofGroups){PIstat[[x]] <- grouped.PIprofiles[[x]][[learningscore]]}
PIstat <- as.data.frame(t(plyr::ldply(PIstat, rbind))) #convert PI list to data.frame
colnames(PIstat) <- unlist(sapply(project.data[["resources"]], '[', 'name')) #add group names as column names to PIstat
#compute standard deviations
SDs<-as.numeric(apply(PIstat, 2, function(x) sd(na.omit(x))))
wil <- project.data[["statistics"]][["single.groups"]][["data"]]==1 ###determine if we need to do single tests
cat("# Learning Score Statistics\n## Statistical tests of single groups against zero")
wilcoxon<-numeric()
for(x in 1:NofGroups){wilcoxon[x] = signif(wilcox.test(PIstat[[x]])$p.value, 3)} #test all groups against zero
#compute Bayes Factor for single group
if(NofGroups==1){
results.bayes=extractBF(ttestBF(na.omit(PIstat[[1]])))
results.bayes <- results.bayes[-c(3,4)] # drop the date and code columns
row.names(results.bayes) <- groupnames #group name as row name
results.bayes <- signif(results.bayes, digits=3) # reduce results to 3 significant digits
} else { #compute Bayes Factors for several groups
results.bayes<-list()
for(x in 1:NofGroups){results.bayes[[x]]=extractBF(ttestBF(na.omit(PIstat[[x]])))} #extract BayesFactors for all groups
results.bayes<-do.call("rbind", results.bayes) #fuse all Bayes results into one dataframe
results.bayes <- results.bayes[-c(3,4)]# drop the date and code columns
row.names(results.bayes) <- groupnames #group name as row name
results.bayes <- signif(results.bayes, digits=3) # reduce results to 3 significant digits
}
# plot PI box plot test against zero
plots.singles<-list(ggplot(melt(PIstat), aes(variable, value)) +
geom_hline(yintercept = 0, colour = "#887000", size = 1.2) +
geom_boxplot(fill = boxcolors, notch = FALSE, outlier.color=NA, width=0.8, size=0.6) +
geom_jitter(data = melt(PIstat), aes(variable, value), position=position_jitter(0.3), shape=21, size=3, colour="black", fill="grey50", alpha=0.4) +
ggtitle("Wilcoxon") +
scale_y_continuous(breaks = seq(-1, 1, .2)) +
theme_light(base_size = 16) + theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_blank() ,panel.border = element_rect(size = 0.5, linetype = "solid", colour = "black", fill=NA)) +
theme(axis.text.y = element_text(size=18))+ ylab(paste("PI", learningscore, " [rel. units]", sep = ""))+ xlab("Groups")+ theme(aspect.ratio=3/NofGroups)+
samplesizes.annotate(boxes, samplesizes) +
wilcox.annotate(boxes, wilcoxon))
cat("## Statistical tests between two groups")
utest = signif(wilcox.test(PIstat[[1]],PIstat[[2]])$p.value, 3) #compare the two groups with a U-test and collect p-value
w.statistic = signif(wilcox.test(PIstat[[1]],PIstat[[2]])$statistic, 3)
#compute effect size Cohen's D
cohend = signif(cohen.d(na.omit(PIstat[,1]), na.omit(PIstat[,2]))$estimate, 3)
#calculate statistical power
alt = project.data[["statistics"]][["two.groups"]][["power"]]
power=signif(pwr.t2n.test(n1 = samplesizes[1], n2= samplesizes[2], d = cohend, alternative = alt, sig.level = signif[1])$power, 3)
cat("## Estimation statistics")
PIest=na.omit(melt(PIstat)) #create a dataframe that fits estimation stat requirements and remove missing PIs
unpaired_mean_diff <- dabest(PIest, variable, value, idx = groupnames, paired = FALSE) #create estimation results list
print(plot(unpaired_mean_diff)) #plot results
learningscore=project.data[["statistics"]][["learning-score"]][["data"]] #get the PI that is going to be tested
if(!om){samplesizes<-as.numeric(apply(PIstat, 2, function(x) length(na.omit(x))))}
#create new dataframe with only the chosen PI values
PIstat <- list()
for(x in 1:NofGroups){PIstat[[x]] <- grouped.PIprofiles[[x]][[learningscore]]}
PIstat <- as.data.frame(t(plyr::ldply(PIstat, rbind))) #convert PI list to data.frame
colnames(PIstat) <- unlist(sapply(project.data[["resources"]], '[', 'name')) #add group names as column names to PIstat
#compute standard deviations
SDs<-as.numeric(apply(PIstat, 2, function(x) sd(na.omit(x))))
View(PIstat)
wil <- project.data[["statistics"]][["single.groups"]][["data"]]==1 ###determine if we need to do single tests
wil <- project.data[["statistics"]][["single.groups"]][["data"]]==1 ###determine if we need to do single tests
cat("# Learning Score Statistics\n## Statistical tests of single groups against zero")
wilcoxon<-numeric()
for(x in 1:NofGroups){wilcoxon[x] = signif(wilcox.test(PIstat[[x]])$p.value, 3)} #test all groups against zero
#compute Bayes Factor for single group
if(NofGroups==1){
results.bayes=extractBF(ttestBF(na.omit(PIstat[[1]])))
results.bayes <- results.bayes[-c(3,4)] # drop the date and code columns
row.names(results.bayes) <- groupnames #group name as row name
results.bayes <- signif(results.bayes, digits=3) # reduce results to 3 significant digits
} else { #compute Bayes Factors for several groups
results.bayes<-list()
for(x in 1:NofGroups){results.bayes[[x]]=extractBF(ttestBF(na.omit(PIstat[[x]])))} #extract BayesFactors for all groups
results.bayes<-do.call("rbind", results.bayes) #fuse all Bayes results into one dataframe
results.bayes <- results.bayes[-c(3,4)]# drop the date and code columns
row.names(results.bayes) <- groupnames #group name as row name
results.bayes <- signif(results.bayes, digits=3) # reduce results to 3 significant digits
}
# plot PI box plot test against zero
plots.singles<-list(ggplot(melt(PIstat), aes(variable, value)) +
geom_hline(yintercept = 0, colour = "#887000", size = 1.2) +
geom_boxplot(fill = boxcolors, notch = FALSE, outlier.color=NA, width=0.8, size=0.6) +
geom_jitter(data = melt(PIstat), aes(variable, value), position=position_jitter(0.3), shape=21, size=3, colour="black", fill="grey50", alpha=0.4) +
ggtitle("Wilcoxon") +
scale_y_continuous(breaks = seq(-1, 1, .2)) +
theme_light(base_size = 16) + theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_blank() ,panel.border = element_rect(size = 0.5, linetype = "solid", colour = "black", fill=NA)) +
theme(axis.text.y = element_text(size=18))+ ylab(paste("PI", learningscore, " [rel. units]", sep = ""))+ xlab("Groups")+ theme(aspect.ratio=3/NofGroups)+
samplesizes.annotate(boxes, samplesizes) +
wilcox.annotate(boxes, wilcoxon))
#add table with results and plot
plots.singles[[2]]<-tableGrob(results.bayes)
grid.arrange(grobs = plots.singles, ncol=2)
cat("## Statistical tests between two groups")
utest = signif(wilcox.test(PIstat[[1]],PIstat[[2]])$p.value, 3) #compare the two groups with a U-test and collect p-value
w.statistic = signif(wilcox.test(PIstat[[1]],PIstat[[2]])$statistic, 3)
#compute effect size Cohen's D
cohend = signif(cohen.d(na.omit(PIstat[,1]), na.omit(PIstat[,2]))$estimate, 3)
#calculate statistical power
alt = project.data[["statistics"]][["two.groups"]][["power"]]
power=signif(pwr.t2n.test(n1 = samplesizes[1], n2= samplesizes[2], d = cohend, alternative = alt, sig.level = signif[1])$power, 3)
#calculate Bayes Factor
bayesF=extractBF(ttestBF(na.omit(PIstat[[1]]), na.omit(PIstat[[2]])))
#calculate FPR for priors set in project file#
#run first prior
prior=priorval[1]
out=calc.FPR(samplesizes,utest,prior,abs(cohend))  #output=c(FPR,x0,y0,x1,y1)
fpz1=out[1]
#run second prior
prior=priorval[2]
out=calc.FPR(samplesizes,utest,prior,abs(cohend))  #output=c(FPR,x0,y0,x1,y1)
fpz2=out[1]
#Power and likelihood ratio: NB for two sided test, need 2*y0
LR=out[5]/(2*out[3])        #lik ratio (Hi1/H0) =y1/2*y0
#make tidy table of results
results.utest<-data.frame(values=c(signif[1],
w.statistic,
cohend,
power,
signif(bayesF$bf, 3),
signif(bayesF$error, 3),
signif(fpz1, 3),
signif(fpz2, 3),
signif(LR, 3)))
rownames(results.utest)<-c("Significance level",
"MW U-Test, W",
"Cohen's D",
"stat. Power",
"Bayes Factor",
"Bayes Factor error",
paste("FP risk, prior ",priorval[1]),
paste("FP risk, prior ",priorval[2]),
"Likelihood Ratio")
# plot two PIs with asterisks
plots.2test<-list(ggplot(melt(PIstat), aes(variable, value)) +
geom_hline(yintercept = 0, colour = "#887000", size = 1.2) +
geom_boxplot(fill = boxcolors, notch = TRUE, outlier.color=NA, width=0.8, size=0.6) +
geom_jitter(data = melt(PIstat), aes(variable, value), position=position_jitter(0.3), shape=21, size=3, colour="black", fill="grey50", alpha=0.4) +
ggtitle(paste("U-Test, p=", utest)) +
scale_y_continuous(breaks = seq(-1, 1, .2)) +
theme_light(base_size = 16) + theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_blank(), panel.border = element_rect(size = 0.5, linetype = "solid", colour = "black", fill=NA)) +
theme(axis.text.y = element_text(size=18))+ ylab(paste("PI", learningscore, " [rel. units]", sep = ""))+ xlab("Groups")+ theme(aspect.ratio=3/NofGroups)+
geom_signif(comparisons = list(c(colnames(PIstat[1]), colnames(PIstat[2]))),
map_signif_level= c("***"= signif[3],"**"= signif[2], "*"= signif[1]),
textsize=8, vjust=0.5) +
samplesizes.annotate(boxes, samplesizes))
#add table with results and plot
plots.2test[[2]]<-tableGrob(results.utest)
grid.arrange(grobs = plots.2test, ncol=2)
cat("## Estimation statistics")
PIest=na.omit(melt(PIstat)) #create a dataframe that fits estimation stat requirements and remove missing PIs
unpaired_mean_diff <- dabest(PIest, variable, value, idx = groupnames, paired = FALSE) #create estimation results list
print(plot(unpaired_mean_diff)) #plot results
setwd("B:/GitHub/DTSevaluations")
source('B:/GitHub/DTSevaluations/HTML_DTS_project.R', echo=TRUE)
learningscore=project.data[["statistics"]][["learning-score"]][["data"]] #get the PI that is going to be tested
if(!om){samplesizes<-as.numeric(apply(PIstat, 2, function(x) length(na.omit(x))))}
learningscore=project.data[["statistics"]][["learning-score"]][["data"]] #get the PI that is going to be tested
#create new dataframe with only the chosen PI values
PIstat <- list()
for(x in 1:NofGroups){PIstat[[x]] <- grouped.PIprofiles[[x]][[learningscore]]}
PIstat <- as.data.frame(t(plyr::ldply(PIstat, rbind))) #convert PI list to data.frame
colnames(PIstat) <- unlist(sapply(project.data[["resources"]], '[', 'name')) #add group names as column names to PIstat
#compute standard deviations
SDs<-as.numeric(apply(PIstat, 2, function(x) sd(na.omit(x))))
if(!om){samplesizes<-as.numeric(apply(PIstat, 2, function(x) length(na.omit(x))))}
wil <- project.data[["statistics"]][["single.groups"]][["data"]]==1 ###determine if we need to do single tests
cat("# Learning Score Statistics\n## Statistical tests of single groups against zero")
wilcoxon<-numeric()
for(x in 1:NofGroups){wilcoxon[x] = signif(wilcox.test(PIstat[[x]])$p.value, 3)} #test all groups against zero
#compute Bayes Factor for single group
if(NofGroups==1){
results.bayes=extractBF(ttestBF(na.omit(PIstat[[1]])))
results.bayes <- results.bayes[-c(3,4)] # drop the date and code columns
row.names(results.bayes) <- groupnames #group name as row name
results.bayes <- signif(results.bayes, digits=3) # reduce results to 3 significant digits
} else { #compute Bayes Factors for several groups
results.bayes<-list()
for(x in 1:NofGroups){results.bayes[[x]]=extractBF(ttestBF(na.omit(PIstat[[x]])))} #extract BayesFactors for all groups
results.bayes<-do.call("rbind", results.bayes) #fuse all Bayes results into one dataframe
results.bayes <- results.bayes[-c(3,4)]# drop the date and code columns
row.names(results.bayes) <- groupnames #group name as row name
results.bayes <- signif(results.bayes, digits=3) # reduce results to 3 significant digits
}
# plot PI box plot test against zero
plots.singles<-list(ggplot(melt(PIstat), aes(variable, value)) +
geom_hline(yintercept = 0, colour = "#887000", size = 1.2) +
geom_boxplot(fill = boxcolors, notch = FALSE, outlier.color=NA, width=0.8, size=0.6) +
geom_jitter(data = melt(PIstat), aes(variable, value), position=position_jitter(0.3), shape=21, size=3, colour="black", fill="grey50", alpha=0.4) +
ggtitle("Wilcoxon") +
scale_y_continuous(breaks = seq(-1, 1, .2)) +
theme_light(base_size = 16) + theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_blank() ,panel.border = element_rect(size = 0.5, linetype = "solid", colour = "black", fill=NA)) +
theme(axis.text.y = element_text(size=18))+ ylab(paste("PI", learningscore, " [rel. units]", sep = ""))+ xlab("Groups")+ theme(aspect.ratio=3/NofGroups)+
samplesizes.annotate(boxes, samplesizes) +
wilcox.annotate(boxes, wilcoxon))
#add table with results and plot
plots.singles[[2]]<-tableGrob(results.bayes)
grid.arrange(grobs = plots.singles, ncol=2)
cat("## Statistical tests between two groups")
utest = signif(wilcox.test(PIstat[[1]],PIstat[[2]])$p.value, 3) #compare the two groups with a U-test and collect p-value
w.statistic = signif(wilcox.test(PIstat[[1]],PIstat[[2]])$statistic, 3)
#compute effect size Cohen's D
cohend = signif(cohen.d(na.omit(PIstat[,1]), na.omit(PIstat[,2]))$estimate, 3)
#calculate statistical power
alt = project.data[["statistics"]][["two.groups"]][["power"]]
power=signif(pwr.t2n.test(n1 = samplesizes[1], n2= samplesizes[2], d = cohend, alternative = alt, sig.level = signif[1])$power, 3)
#calculate Bayes Factor
bayesF=extractBF(ttestBF(na.omit(PIstat[[1]]), na.omit(PIstat[[2]])))
#calculate FPR for priors set in project file#
#run first prior
prior=priorval[1]
out=calc.FPR(samplesizes,utest,prior,abs(cohend))  #output=c(FPR,x0,y0,x1,y1)
fpz1=out[1]
#run second prior
prior=priorval[2]
out=calc.FPR(samplesizes,utest,prior,abs(cohend))  #output=c(FPR,x0,y0,x1,y1)
fpz2=out[1]
#Power and likelihood ratio: NB for two sided test, need 2*y0
LR=out[5]/(2*out[3])        #lik ratio (Hi1/H0) =y1/2*y0
#make tidy table of results
results.utest<-data.frame(values=c(signif[1],
w.statistic,
cohend,
power,
signif(bayesF$bf, 3),
signif(bayesF$error, 3),
signif(fpz1, 3),
signif(fpz2, 3),
signif(LR, 3)))
rownames(results.utest)<-c("Significance level",
"MW U-Test, W",
"Cohen's D",
"stat. Power",
"Bayes Factor",
"Bayes Factor error",
paste("FP risk, prior ",priorval[1]),
paste("FP risk, prior ",priorval[2]),
"Likelihood Ratio")
# plot two PIs with asterisks
plots.2test<-list(ggplot(melt(PIstat), aes(variable, value)) +
geom_hline(yintercept = 0, colour = "#887000", size = 1.2) +
geom_boxplot(fill = boxcolors, notch = TRUE, outlier.color=NA, width=0.8, size=0.6) +
geom_jitter(data = melt(PIstat), aes(variable, value), position=position_jitter(0.3), shape=21, size=3, colour="black", fill="grey50", alpha=0.4) +
ggtitle(paste("U-Test, p=", utest)) +
scale_y_continuous(breaks = seq(-1, 1, .2)) +
theme_light(base_size = 16) + theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_blank(), panel.border = element_rect(size = 0.5, linetype = "solid", colour = "black", fill=NA)) +
theme(axis.text.y = element_text(size=18))+ ylab(paste("PI", learningscore, " [rel. units]", sep = ""))+ xlab("Groups")+ theme(aspect.ratio=3/NofGroups)+
geom_signif(comparisons = list(c(colnames(PIstat[1]), colnames(PIstat[2]))),
map_signif_level= c("***"= signif[3],"**"= signif[2], "*"= signif[1]),
textsize=8, vjust=0.5) +
samplesizes.annotate(boxes, samplesizes))
#add table with results and plot
plots.2test[[2]]<-tableGrob(results.utest)
grid.arrange(grobs = plots.2test, ncol=2)
cat("## Estimation statistics")
PIest=na.omit(melt(PIstat)) #create a dataframe that fits estimation stat requirements and remove missing PIs
unpaired_mean_diff <- dabest(PIest, variable, value, idx = groupnames, paired = FALSE) #create estimation results list
print(plot(unpaired_mean_diff)) #plot results
cat("## Estimation statistics")
PIest=na.omit(melt(PIstat)) #create a dataframe that fits estimation stat requirements and remove missing PIs
unpaired_mean_diff <- dabest(PIest, variable, value, idx = groupnames, paired = FALSE) #create estimation results list
print(plot(unpaired_mean_diff)) #plot results
setwd("B:/GitHub/DTSevaluations")
source('B:/GitHub/DTSevaluations/HTML_DTS_project.R', echo=TRUE)
vignette("Using dabestr", package = "dabestr")
unpaired_mean_diff <- dabest(PIest, variable, value, idx = groupnames, paired = FALSE, func = cohens_d) #create estimation results list
unpaired_mean_diff <- dabest(PIest, variable, value, idx = groupnames, paired = FALSE, func = "cohens_d") #create estimation results list
unpaired_mean_diff <- dabest(PIest, variable, value, idx = groupnames, paired = FALSE, func = median) #create estimation results list
plot(unpaired_mean_diff)
unpaired_mean_diff <- dabest(PIest, variable, value, idx = groupnames, paired = FALSE, func = cohend) #create estimation results list
unpaired_mean_diff <- dabest(PIest, variable, value, idx = groupnames, paired = FALSE, func = cohen_d) #create estimation results list
unpaired_mean_diff <- dabest(PIest, variable, value, idx = groupnames, paired = FALSE, func = cohen.d) #create estimation results list
unpaired_mean_diff <- dabest(PIest, variable, value, idx = groupnames, paired = FALSE, func = cohen.d) #create estimation results list
unpaired_mean_diff <- dabest(PIest, variable, value, idx = groupnames, paired = FALSE, func = cohen-d) #create estimation results list
unpaired_mean_diff <- dabest(PIest, variable, value, idx = groupnames, paired = FALSE, func = cohens_d) #create estimation results list
unpaired_mean_diff <- dabest(PIest, variable, value, idx = groupnames, paired = FALSE, func = cohen_d) #create estimation results list
unpaired_mean_diff <- dabest(PIest, variable, value, idx = groupnames, paired = FALSE, func = cohend) #create estimation results list
unpaired_median_diff <- dabest(PIest, variable, value, idx = groupnames, paired = FALSE, func = median) #create estimation results list
plot(unpaired_median_diff)
View(unpaired_median_diff)
setwd("B:/GitHub/DTSevaluations")
source('B:/GitHub/DTSevaluations/HTML_DTS_project.R', echo=TRUE)
source('B:/GitHub/DTSevaluations/HTML_DTS_project.R', echo=TRUE)
