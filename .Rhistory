install.packages("Rcpp")
install.packages("Rcpp")
rm(list=ls()) #clean memory
gc()          #collect garbage
install.packages("Rcpp")
install.packages("Rcpp")
load("~/buridan_ottavia.RData")
View(bf.activity)
bf.activity[3]
bf.activity$bayesFactor
bf.activity[[3]]
bf.activity[3]
bf.activity[1]
bf.activity[2]
bf.activity[3]
bf.activity[4]
bf.activity$bf
bf.activity[3]$bf
bf.activity[,1]
bf.activity[,2]
bf.activity
bf.distance
bf.fixation
bf.meander
bf.speed
View(buri.data)
mean(buri.data$median_speed[1:21])
mean(buri.data$median_speed[22:42])
sd(buri.data$median_speed[1:21])
sd(buri.data$median_speed[22:42])
sd(buri.data$median_speed)
sd(buri.data$meander)
mean(buri.data$meander[22:42])
mean(buri.data$meander[1:21])
sd(buri.data$activitytime_ST)
mean(buri.data$activitytime_ST[1:21])
mean(buri.data$activitytime_ST[22:42])
mean(buri.data$stripe_deviation[1:21])
mean(buri.data$stripe_deviation[2:42])
mean(buri.data$stripe_deviation)
sd(buri.data$stripe_deviation)
cohend.stripe = signif(cohen.d(buri.data$stripe_deviation[1:21], buri.data$stripe_deviation[2:42])$estimate, 3)
knitr::opts_chunk$set(echo = TRUE)
library(effsize)
cohend.stripe = signif(cohen.d(buri.data$stripe_deviation[1:21], buri.data$stripe_deviation[2:42])$estimate, 3)
power.stripe=signif(pwr.t2n.test(n1 = 21, n2= 21, d = cohend.stripe, alternative = alt, sig.level = 0.05)$power, 3)
library(pwr)
power.stripe=signif(pwr.t2n.test(n1 = 21, n2= 21, d = cohend.stripe, alternative = alt, sig.level = 0.05)$power, 3)
power.stripe=signif(pwr.t2n.test(n1 = 21, n2= 21, d = cohend.stripe, alternative = two.sided, sig.level = 0.05)$power, 3)
power.stripe=signif(pwr.t2n.test(n1 = 21, n2= 21, d = cohend.stripe, alternative = "two.sided", sig.level = 0.05)$power, 3)
sd(buri.data$stripe_deviation[1:21])
sd(buri.data$stripe_deviation[2:42])
cohen.d(buri.data$stripe_deviation[1:21], buri.data$stripe_deviation[2:42])
cohen.d(buri.data$stripe_deviation[2:42], buri.data$stripe_deviation[1:21])
(mean(buri.data$stripe_deviation[1:21])-mean(buri.data$stripe_deviation[2:42]))/sd(buri.data$stripe_deviation)
cohen.d(buri.data$stripe_deviation[2:42], buri.data$stripe_deviation[1:21], hedges.correction=TRUE)
save.image("~/buridan_ottavia.RData")
power.stripe=signif(pwr.t.test(n = 21, d = cohend.stripe, alternative = "two.sided", sig.level = 0.05)$power, 3)
pwr.t.test(n = 21, d = cohend.stripe, alternative = "two.sided", sig.level = 0.05
)
pwr.t2n.test(n1 = 21, n2= 21, d = cohend.stripe, alternative = two.sided, sig.level = 0.05)
pwr.t2n.test(n1 = 21, n2= 21, d = cohend.stripe, alternative = "two.sided", sig.level = 0.05)
(mean(buri.data$stripe_deviation[1:21])-mean(buri.data$stripe_deviation[2:42]))/sqrt((sd(buri.data$stripe_deviation[1:21]^2)-sd(buri.data$stripe_deviation[2:42]^2))/2)
(mean(buri.data$stripe_deviation[1:21])-mean(buri.data$stripe_deviation[2:42]))/sqrt((sd(buri.data$stripe_deviation[1:21])^2-sd(buri.data$stripe_deviation[2:42])^2)/2)
sd(buri.data$stripe_deviation[1:21])^2
sd(buri.data$stripe_deviation[1:21])^2-sd(buri.data$stripe_deviation[2:42])^2
(mean(buri.data$stripe_deviation[1:21])-mean(buri.data$stripe_deviation[2:42]))/sqrt((sd(buri.data$stripe_deviation[1:21])^2+sd(buri.data$stripe_deviation[2:42])^2)/2)
cohen.d(buri.data$stripe_deviation[2:42], buri.data$stripe_deviation[1:21], hedges.correction=TRUE, within=FALSE)
cohen.d(buri.data$stripe_deviation[2:42], buri.data$stripe_deviation[1:21], hedges.correction=TRUE, within=TRUE)
cohen.d(buri.data$stripe_deviation[2:42], buri.data$stripe_deviation[1:21], hedges.correction=TRUE, pooled = =TRUE)
cohen.d(buri.data$stripe_deviation[2:42], buri.data$stripe_deviation[1:21], hedges.correction=TRUE, pooled = TRUE)
cohen.d(buri.data$stripe_deviation[2:42], buri.data$stripe_deviation[1:21], hedges.correction=TRUE, pooled = FALSE)
edit(effsize:::cohen.d.default)
edit(effsize:::cohen.d.default)
save.image("~/buridan_ottavia.RData")
load("B:/GitHub/DTSevaluations/example data/colorlearning/.RData")
View(PIstat)
PIstat[[1]]
PIstat[[,1]]
if(samplesizes[1]==samplesizes[2]){equalN=TRUE}else{equalN=FALSE}   #deterine if the samplesizes are identical
PIg <- as.factor(c(rep(1, samplesizes[1]), rep(2, samplesizes[2]))) #make a grouping variable to test for homogeneity of variance
PIv = c(na.omit(PIstat[[1]]), na.omit(PIstat[[1]]))                 #combine the two PI samples into one value vector to test for homogeneity of variance
if(fligner.test(PIv,PIg)<0.05){hv=FALSE}else{hv=TRUE}               #test for homogeneity of variance and set hv TRUE/FALSE
samplesizes[1]=length(PIstat[1])
samplesizes[1]=length(PIstat[[1]])
samplesizes[2]=length(PIstat[[2]])
samplesizes[2]=length(na.omit(PIstat[[2]]))
samplesizes[1]=length(na.omit(PIstat[[1]]))
PIstat[[1]]
PIstat[1]
PIv = c(na.omit(PIstat[[1]]), na.omit(PIstat[[2]]))                 #combine the two PI samples into one value vector to test for homogeneity of variance
PIg
PIv
PIv = c(na.omit(PIstat[1]), na.omit(PIstat[2]))                 #combine the two PI samples into one value vector to test for homogeneity of variance
PIv = c(na.omit(PIstat[[1]]), na.omit(PIstat[[2]]))                 #combine the two PI samples into one value vector to test for homogeneity of variance
fligner.test(PIv,PIg)
fktest=fligner.test(PIv,PIg)
fktest$p.value
if(samplesizes[1]==samplesizes[2]){equalN=TRUE}else{equalN=FALSE}   #deterine if the samplesizes are identical
PIg <- as.factor(c(rep(1, samplesizes[1]), rep(2, samplesizes[2]))) #make a grouping variable to test for homogeneity of variance
PIv = c(na.omit(PIstat[[1]]), na.omit(PIstat[[2]]))                 #combine the two PI samples into one value vector to test for homogeneity of variance
if(fligner.test(PIv,PIg)$p.value<0.05){hv=FALSE}else{hv=TRUE}       #test for homogeneity of variance and set hv TRUE/FALSE
if(equalN & hv){hedges=FALSE}else{hedges=TRUE}                      #test if we need to apply Hedge's correction
cohend = signif(cohen.d(PIstat[,1], PIstat[,2], na.rm = TRUE, hedges.correction = hedges)$estimate, 3)
cohend = signif(cohen.d(PIstat[,1], PIstat[,2], na.rm = TRUE, hedges.correction = hedges)$estimate, 3)
PIstat[,1]
PIstat[[1]]
cohend = signif(cohen.d(PIstat[,1], PIstat[,2], na.rm = TRUE, hedges.correction = hedges, pooled = FALSE)$estimate, 3)
cohend = signif(cohen.d(PIv, PIg, hedges.correction = hedges)$estimate, 3)
cohend = signif(cohen.d(PIv, PIg)$estimate, 3)
cohend = signif(cohen.d(PIv, PIg, hedges.correction = hedges)$estimate, 3)
power=signif(pwr.t2n.test(n1 = samplesizes[1], n2= samplesizes[2], d = cohend, alternative = alt, sig.level = signif[1])$power, 3)
cohend = (mean(PIstat[[1]])-mean(PIstat[[2]]))/sqrt((sd(PIstat[[1]]^2+PIstat[[1]]^2))/2)
(mean(PIstat[[1]])-mean(PIstat[[2]])
)
mean(PIstat[[1]])
PIstat[[1]]
mean(PIstat[1])
mean(PIstat[,1])
mean(na.omit(PIstat[,1]))
sd(PIstat[[1]])
sd(PIstat[[2]])
PIstat[[1]])
sd(PIstat[[1]])
sqrt((sd(na.omit(PIstat[[1]]))^2+sd(na.omit(PIstat[[2]]))^2)/2)
(mean(na.omit(PIstat[[1]]))-mean(na.omit(PIstat[[2]])))
cohend = (mean(na.omit(PIstat[[1]]))-mean(na.omit(PIstat[[2]])))/sqrt((sd(na.omit(PIstat[[1]]))^2+sd(na.omit(PIstat[[2]]))^2)/2)
cohend = signif(cohen.d(PIv, PIg, hedges.correction = hedges)$estimate, 3)
load("B:/GitHub/DTSevaluations/.RData")
View(PIstat)
View(PIstatCombined)
cohend = signif((mean(na.omit(PIstat[[1]]))-mean(na.omit(PIstat[[2]])))/sqrt((sd(na.omit(PIstat[[1]]))^2+sd(na.omit(PIstat[[2]]))^2)/2), 3)
View(PIstat)
install.packages(c("DescTools", "questionr"))
install.packages(c("glue", "gtools", "lattice", "purrr", "Rcpp", "reshape2", "rlang", "tibble", "zoo"))
install.packages(c("glue", "gtools", "lattice", "purrr", "Rcpp", "reshape2", "rlang", "tibble", "zoo"))
install.packages(c("glue", "gtools", "lattice", "purrr", "Rcpp", "reshape2", "rlang", "tibble", "zoo"))
install.packages(c("glue", "gtools", "lattice", "purrr", "Rcpp", "reshape2", "rlang", "tibble", "zoo"))
install.packages(c("glue", "gtools", "lattice", "purrr", "Rcpp", "reshape2", "rlang", "tibble", "zoo"))
install.packages(c("glue", "gtools", "lattice", "purrr", "Rcpp", "reshape2", "rlang", "tibble", "zoo"))
install.packages(c("glue", "gtools", "lattice", "purrr", "Rcpp", "reshape2", "rlang", "tibble", "zoo"))
install.packages(c("glue", "gtools", "lattice", "purrr", "Rcpp", "reshape2", "rlang", "tibble", "zoo"))
install.packages(c("glue", "gtools", "lattice", "purrr", "Rcpp", "reshape2", "rlang", "tibble", "zoo"))
install.packages(c("glue", "gtools", "lattice", "purrr", "Rcpp", "reshape2", "rlang", "tibble", "zoo"))
rm(list=ls()) #clean memory
gc()          #collect garbage
install.packages(c("glue", "gtools", "lattice", "purrr", "Rcpp", "rlang", "tibble"))
install.packages(c("lattice", "Rcpp", "rlang"))
install.packages("rlang")
install.packages("rlang")
knitr::opts_chunk$set(echo = TRUE)
lengths(project.data["resources"])
lengths(project.data["resources"])*5
View(PIprofile)
sapply(PIprofile, as.character)
library(tidyr)
install.packages("readr")
library(readr)
format_delim(PIprofile)
format_delim(PIprofile, delim=tab
)
format_delim(PIprofile, delim=",")
install.packages(c("backports", "boot", "broom", "callr", "car", "carData", "class", "dabestr", "dbplyr", "DescTools", "devtools", "dplyr", "effsize", "ellipsis", "fs", "ggplot2", "git2r", "glue", "gtools", "haven", "httpuv", "isoband", "KernSmooth", "labelled", "lattice", "lme4", "lubridate", "maptools", "MASS", "modelr", "multcomp", "nlme", "nnet", "openxlsx", "pillar", "pkgbuild", "pkgload", "ps", "purrr", "quantreg", "questionr", "Rcpp", "RCurl", "reactable", "reshape2", "rex", "rlang", "rmarkdown", "rversions", "scales", "seewave", "sp", "spatial", "survival", "tibble", "tidyr", "tidyselect", "tinytex", "usethis", "vctrs", "withr", "xfun", "xml2", "zoo"))
install.packages(c("dplyr", "glue", "purrr", "Rcpp", "rlang", "tibble", "tidyr", "vctrs"))
install.packages(c("dplyr", "glue", "purrr", "Rcpp", "rlang", "tibble", "tidyr", "vctrs"))
install.packages(c("dplyr", "glue", "purrr", "Rcpp", "rlang", "tibble", "tidyr", "vctrs"))
install.packages(c("dplyr", "glue", "purrr", "Rcpp", "rlang", "tibble", "tidyr", "vctrs"))
install.packages(c("dplyr", "glue", "purrr", "Rcpp", "rlang", "tibble", "tidyr", "vctrs"))
install.packages(c("dplyr", "glue", "purrr", "Rcpp", "rlang", "tibble", "tidyr", "vctrs"))
install.packages(c("dplyr", "glue", "purrr", "Rcpp", "rlang", "tibble", "tidyr", "vctrs"))
install.packages(c("dplyr", "glue", "purrr", "Rcpp", "rlang", "tibble", "tidyr", "vctrs"))
install.packages(c("dplyr", "glue", "purrr", "Rcpp", "rlang", "tibble", "tidyr", "vctrs"))
install.packages(c("dplyr", "glue", "purrr", "Rcpp", "rlang", "tibble", "tidyr", "vctrs"))
install.packages(c("dplyr", "glue", "purrr", "Rcpp", "rlang", "tibble", "tidyr", "vctrs"))
install.packages(c("dplyr", "glue", "purrr", "Rcpp", "rlang", "tibble", "tidyr", "vctrs"))
install.packages(c("dplyr", "glue", "purrr", "Rcpp", "rlang", "tibble", "tidyr", "vctrs"))
install.packages(c("dplyr", "glue", "purrr", "Rcpp", "rlang", "tibble", "tidyr", "vctrs"))
install.packages(c("dplyr", "glue", "purrr", "Rcpp", "rlang", "tibble", "tidyr", "vctrs"))
install.packages(c("dplyr", "glue", "purrr", "Rcpp", "rlang", "tibble", "tidyr", "vctrs"))
file.edit(file.path("~", ".Rprofile"))
rm(list=ls())                      #clean memory
gc()                               #collect garbage
if(!is.null(dev.list())) dev.off() #clear plots
install.packages(c("glue", "Rcpp", "rlang", "tibble", "vctrs"))
install.packages("boot")
library(ggplot2)
library(tidyr)
library(dygraphs)
library(grid)
library(reshape2)
library(plyr)
library(dplyr)
library(gridExtra)
library(yaml)
library(ggsignif)
library(effsize)
library(pwr)
library(BayesFactor)
library(genefilter)
library(seewave)
library(lubridate)
library(rmarkdown)
library(markdown)
library(knitr)
library(dabestr)
library(zoo)
library(tidyverse)
library(questionr)
library(data.table)
library(DescTools)
library(magick)
install.packages(c("ggplot2","tidyr","dygraphs","grid","reshape","plyr","dplyr","gridExtra","yaml","ggsignif","effsize","pwr","BayesFactor","genefilter","bioconductor","seewave","lubridate","rmarkdown","markdown","knitr","dabestr","zoo","tidyverse","questionr","data.table","DescTools","magick"),dependencies = TRUE)
install.packages(c("ggplot2", "tidyr", "dygraphs", "grid", "reshape", "plyr", "dplyr", "gridExtra", "yaml", "ggsignif", "effsize", "pwr", "BayesFactor", "genefilter", "bioconductor", "seewave", "lubridate", "rmarkdown", "markdown", "knitr", "dabestr", "zoo", "tidyverse", "questionr", "data.table", "DescTools", "magick"), dependencies = TRUE)
update.packages(ask=FALSE, checkBuilt=TRUE)
library(ggplot2)
library(tidyr)
library(dygraphs)
library(grid)
library(reshape2)
library(plyr)
library(dplyr)
library(gridExtra)
library(yaml)
library(ggsignif)
library(effsize)
library(pwr)
library(BayesFactor)
library(genefilter)
library(seewave)
library(lubridate)
library(rmarkdown)
library(markdown)
library(knitr)
library(dabestr)
library(zoo)
library(tidyverse)
library(questionr)
library(data.table)
library(DescTools)
library(magick)
project.file <- file.choose()
library(yaml)
x=1
groupids <- unlist(sapply(project.data[["resources"]], function(x) x["id"]))                   #get a vector with all group FlyBase IDs
project.data <- yaml.load_file(project.file)
View(project.data)
project.data[["resources"]][[1]][["id"]]
groupids <- unlist(sapply(project.data[["resources"]], function(x) x["id"]))                   #get a vector with all group FlyBase IDs
x=2
groupids <- unlist(sapply(project.data[["resources"]], function(x) x["id"]))                   #get a vector with all group FlyBase IDs
groupids
knitr::opts_chunk$set(echo = TRUE)
paste('<a href="http://flybase.org/reports/',groupids,'">',groupids,'</a>', sep = '')
read.csv(text = groupids)
test=read.csv(text = groupids)
View(test)
test=read.csv(text = groupids[1])
View(test)
read.csv(text = groupids[1])
as.charactor(read.csv(text = groupids[1]))
as.character(read.csv(text = groupids[1]))
as.vector(read.csv(text = groupids[1]))
colnames(read.csv(text = groupids[1]))
colnames(read.csv(text = groupids[2]))
FBids=groupids
for (i in length(FBids)) {
groupid[i]=colnames(read.csv(text = groupids[i]))
}
lapply(colnames(read.csv(text = groupids)))
sapply(colnames(read.csv(text = groupids)))
apply(colnames(read.csv(text = groupids)))
sapply(groupids, colnames(read.csv(text = groupids)))
groupid<-vector
for (i in length(FBids)) {
groupid[i]=colnames(read.csv(text = groupids[i]))
}
groupid<-vector(mode="character", length=length(FBids))
for (i in length(FBids)) {
groupid[i]=colnames(read.csv(text = groupids[i]))
}
groupid
i=1
colnames(read.csv(text = groupids[i]))
groupid[i]=colnames(read.csv(text = groupids[i]))
idlist<-list()
for (i in length(FBids)) {
idlist[[i]]=colnames(read.csv(text = groupids[i]))
}
i=1
idlist[[i]]=colnames(read.csv(text = groupids[i]))
idlist<-list()
for (i in length(FBids)) {
idlist[[i]]=colnames(read.csv(text = groupids[i]))
}
length(FBids)
i=1
idlist[[i]]=colnames(read.csv(text = groupids[i]))
i=2
idlist[[i]]=colnames(read.csv(text = groupids[i]))
idlist<-list()
i=1
idlist[[i]]=colnames(read.csv(text = groupids[i]))
i=2
idlist[[i]]=colnames(read.csv(text = groupids[i]))
idlist<-list()
for (i in length(FBids)) {
idlist[[i]]=colnames(read.csv(text = groupids[i]))
}
idlist<-list()
for (i in length(FBids)) {
idlist[[i]]=colnames(read.csv(text = groupids[i]))
}
idlist<-list()
for (i in length(FBids)) {
idlist[[i]]=colnames(read.csv(text = groupids[i]))
}
idlist<-list()
for (i in length(FBids)) {
idlist[[i]]=colnames(read.csv(text = groupids[i]))
}
idlist<-list()
for (id in length(FBids)) {
idlist[[id]]=colnames(read.csv(text = groupids[id]))
}
id=1
idlist[[id]]=colnames(read.csv(text = groupids[id]))
for (id in length(FBids)) {
idlist[[id]]=colnames(read.csv(text = groupids[id]))
}
idlist<-list(length=length(FBids))
for (id in length(FBids)) {
idlist[[id]]=colnames(read.csv(text = groupids[id]))
}
View(idlist)
idlist<-list()
for (id in 2)) {
idlist[[id]]=colnames(read.csv(text = groupids[id]))
}
idlist<-list()
for (id in 2) {
idlist[[id]]=colnames(read.csv(text = groupids[id]))
}
idlist<-list()
for (id in 2) {
idlist[[id]]=colnames(read.csv(text = groupids[id]))
}
idlist<-list()
for (id in length(FBids)) {
idlist[id]=colnames(read.csv(text = groupids[id]))
}
for (id in length(FBids)) {
idlist[id]=colnames(read.csv(text = groupids[id]))
}
for (id in length(FBids)) {
idlist[id]=colnames(read.csv(text = groupids[id]))
}
for (id in length(FBids)) {
idlist[[id]]=colnames(read.csv(text = groupids[id]))
}
read.csv(text = groupids[id], header = FALSE)
read.csv(text = groupids, header = FALSE)
id.frame=read.csv(text = FBids, header = FALSE)
View(id.frame)
library(yaml)
project.file <- file.choose()
project.data <- yaml.load_file(project.file)
groupids <- unlist(sapply(project.data[["resources"]], function(x) x["id"]))                   #get a vector with all group FlyBase IDs
FBids=groupids
id.frame=read.csv(text = FBids, header = FALSE)
View(id.frame)
paste('<a href="http://flybase.org/reports/',id.frame[,1],'">',id.frame[,1],'</a>', sep = '')
View(id.frame)
paste('<a href="http://flybase.org/reports/',id.frame[1],'">',id.frame[1],'</a>', sep = '')
id.frame<-paste('<a href="http://flybase.org/reports/',id.frame,'">',id.frame,'</a>', sep = '')
id.frame
id.frame=read.csv(text = FBids, header = FALSE)
lapply(id.frame, function(x) paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = ''))
lapply(id.frame, function(x) paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = ''),na.rm=TRUE)
lapply(na.omit(id.frame), function(x) paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = ''),na.rm=TRUE)
lapply(na.omit(id.frame), function(x) paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = ''))
na.omit(id.frame)
test<-lapply(na.omit(id.frame), function(x) paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = ''))
View(test)
test[]<-lapply(na.omit(id.frame), function(x) paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = ''))
test<-as.data.frame(lapply(na.omit(id.frame), function(x) paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = '')))
View(test)
id.frame=na.omit(read.csv(text = FBids, header = FALSE))
View(id.frame)
test<-as.data.frame(lapply(id.frame, function(x) paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = '')))
View(test)
test<-as.data.frame(sapply(id.frame, function(x) paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = '')))
View(test)
test<-as.data.frame(sapply(id.frame, function(x) paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = '')),na.rm=TRUE)
View(test)
id.frame=read.csv(text = FBids, header = FALSE)
test<-as.data.frame(sapply(id.frame, function(x) paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = '')),na.rm=TRUE)
View(test)
rm(test)
test<-as.data.frame(sapply(id.frame, function(x) paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = '')),na.rm=TRUE)
View(test)
test<-as.data.frame(apply(id.frame, function(x) paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = '')),na.rm=TRUE)
View(id.frame)
id.frame=read.csv(text = FBids, header = FALSE)
View(id.frame)
rm(id.frame)
rm(test)
id.frame=read.csv(text = FBids, header = FALSE)
View(id.frame)
test<-as.data.frame(lapply(id.frame, function(x) paste('<a href="http://flybase.org/reports/',!is.na(x),'">',!is.na(x),'</a>', sep = '')))
View(test)
test<-as.data.frame(lapply(id.frame, function(x) paste('<a href="http://flybase.org/reports/',na.omit(x),'">',na.omit(x),'</a>', sep = '')))
View(test)
test<-as.data.frame(lapply(id.frame, function(x) if(!is.na(x)){paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = '')}))
View(test)
rm(test)
test<-as.data.frame(lapply(id.frame, function(x) if(!is.na(x)){paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = '')}))
View(test)
test<-as.data.frame(lapply(id.frame, function(x) ifelse(!is.na(x)){paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = '')}))
test<-as.data.frame(lapply(id.frame, function(x) ifelse(!is.na(x), paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = ''),)))
View(test)
rm(test)
test<-as.data.frame(lapply(id.frame, function(x) ifelse(!is.na(x), paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = ''),)))
View(test)
test<-as.data.frame(lapply(id.frame, function(x) ifelse(!is.na(x), paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = ''),NA)))
View(test)
id.frame[2,2]
read.csv(text = FBids, header = FALSE)
id.frame[2,2]=NA
id.frame[2,3]=NA
View(id.frame)
test<-as.data.frame(lapply(id.frame, function(x) ifelse(!is.na(x), paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = ''),NA)))
View(test)
id.frame=read.csv(text = FBids, header = FALSE)
View(id.frame)
id.frame=read.csv(text = FBids, header = FALSE, na.strings=c("","NA"))
View(id.frame)
test<-as.data.frame(lapply(id.frame, function(x) ifelse(!is.na(x), paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = ''),NA)))
View(test)
rm(test)
rm(id.frame)
id.frame<-as.data.frame(lapply(read.csv(text = FBids, header = FALSE, na.strings=c("","NA")), function(x) ifelse(!is.na(x), paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = ''),NA)))
View(id.frame)
View(id.frame)
shQuote(id.frame)
shQuote(id.frame[1,])
shQuote(id.frame[,1])
shQuote(id.frame[,2])
shQuote(id.frame[1,])
shQuote(na.omit(id.frame[1,]))
shQuote(na.omit(id.frame[2,]))
shQuote(na.omit(id.frame[1,]))
shQuote(na.omit(id.frame[2,]))
shQuote(na.omit(id.frame))
View(id.frame)
collapse(na.omit(id.frame))
paste(id.frame[1,])
paste(id.frame[1,], sep = ",")
paste(id.frame[1,], collapse = ",")
paste(id.frame, collapse = ",")
apply(id.frame,1,paste,collapse=",")
apply(na.omit(id.frame),1,paste,collapse=",")
FBids2=apply(id.frame,1,paste,collapse=",")
FBids2[1]
FBids2[2]
na.omit(id.frame)
id.frame[is.na(id.frame)]<-""
View(id.frame)
FBids2=apply(id.frame,1,paste,collapse=",")
FBids2
gsub(",,",'',FBids2)
tail(FBids2)
sub(",$", "", FBids2)
id.frame<-as.data.frame(lapply(read.csv(text = FBids, header = FALSE, na.strings=c("","NA")), function(x) ifelse(!is.na(x), paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = ''),NA)))
id.frame[is.na(id.frame)]<-"" #remove NAs
FBids=apply(id.frame,1,paste,collapse=",") #create strings
FBids=sub(",$", "", FBids2)  #remove trailing commas
FBids=gsub(",,",'',FBids)    #remove double commas
FBids=gsub(",,,",'',FBids)   #remove triple commas
FBids=gsub(",,,,",'',FBids2) #remove quadruple commas - should be enough
FBids
id.frame<-as.data.frame(lapply(read.csv(text = FBids, header = FALSE, na.strings=c("","NA")), function(x) ifelse(!is.na(x), paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = ''),NA)))
id.frame[is.na(id.frame)]<-"" #remove NAs
FBids=apply(id.frame,1,paste,collapse=",") #create strings
FBids=sub(",$", "", FBids)  #remove trailing commas
FBids=gsub(",,",'',FBids)    #remove double commas
FBids=gsub(",,,",'',FBids)   #remove triple commas
FBids=gsub(",,,,",'',FBids) #remove quadruple commas - should be enough
FBids
id.frame<-as.data.frame(lapply(read.csv(text = FBids, header = FALSE, na.strings=c("","NA")), function(x) ifelse(!is.na(x), paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = ''),NA)))
id.frame[is.na(id.frame)]<-"" #remove NAs
FBids=apply(id.frame,1,paste,collapse=",") #create strings
FBids
rm(FBids)
rm(FBids2)
FBids=groupids
id.frame<-as.data.frame(lapply(read.csv(text = FBids, header = FALSE, na.strings=c("","NA")), function(x) ifelse(!is.na(x), paste('<a href="http://flybase.org/reports/',x,'">',x,'</a>', sep = ''),NA)))
id.frame[is.na(id.frame)]<-"" #remove NAs
View(id.frame)
FBids=apply(id.frame,1,paste,collapse=",") #create strings
FBids
FBids=sub(",$", "", FBids)  #remove trailing commas
FBids
FBids=gsub(",,",'',FBids)    #remove double commas
FBids
FBids=apply(id.frame,1,paste,collapse=",") #create strings
FBids
groupnames=c("wtb","rut","control","experimental")
anyDuplicated(groupnames)
groupnames=c("wtb","rut","control","experimental","experimental")
anyDuplicated(groupnames)
groupnames[anyDuplicated(groupnames)]
source('B:/GitHub/DTSevaluations/HTML_DTS_project.R', echo=TRUE)
